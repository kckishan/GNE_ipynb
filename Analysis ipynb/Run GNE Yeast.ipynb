{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import LoadData as data\n",
    "import numpy as np\n",
    "from GNE import GNE\n",
    "from evaluation import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_seq(seq, num_splits):\n",
    "        newseq = []\n",
    "        splitsize = 1.0/num_splits*len(seq)\n",
    "        for i in range(num_splits):\n",
    "                newseq.append(seq[int(round(i*splitsize)):int(round((i+1)*splitsize))])\n",
    "        return newseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './data/yeast/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneids = pd.read_csv(path + \"gene_ids.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading [./data/yeast/edgelist_biogrid.txt]...\n"
     ]
    }
   ],
   "source": [
    "num_genes = geneids.shape[0]\n",
    "link_file = path + \"edgelist_biogrid.txt\"\n",
    "\n",
    "adj = load_network(link_file, num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544652.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_for_comparison(path, adj):\n",
    "    print(\"Creating 2 split of data\")\n",
    "    g = nx.Graph(adj)\n",
    "    adj = nx.to_scipy_sparse_matrix(g)\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "\n",
    "    # Split link information to train and validation with test split size\n",
    "    edgelist = convertAdjMatrixToSortedRankTSV(adj.todense())\n",
    "    geneids = edgelist.iloc[:, :2]\n",
    "    col1 = np.array(geneids).min(axis=1).astype(int)\n",
    "    col2 = np.array(geneids).max(axis=1).astype(int)\n",
    "    col3 = np.array(edgelist.iloc[:, 2])\n",
    "    data_df = pd.DataFrame()\n",
    "    data_df['i'] = col1\n",
    "    data_df['j'] = col2\n",
    "    data_df['k'] = col3\n",
    "    data_df = data_df.drop_duplicates()\n",
    "\n",
    "    pos_edges = data_df.loc[data_df.iloc[:, 2] == 1]\n",
    "    neg_edgelist = data_df.loc[data_df.iloc[:, 2] == 0]\n",
    "    ind = random.sample(range(len(neg_edgelist)), pos_edges.shape[0])\n",
    "    neg_edges = pd.DataFrame(np.random.permutation(neg_edgelist.values))\n",
    "    neg_edges = neg_edges.iloc[ind, :]\n",
    "\n",
    "#     assert set(map(tuple, pos_edges)).isdisjoint(set(map(tuple, neg_edges)))\n",
    "    return pos_edges, neg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos, X_neg = create_dataset_for_comparison(path, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pos, X_neg = X_pos.values, X_neg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_pos, X_neg = X_pos.astype(int), X_neg.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomized_indices = np.random.permutation(range(len(X_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_splits = split_seq(range(len(X_pos)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_index = randomized_indices[index_splits[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_index = randomized_indices[index_splits[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_edges = X_pos[train_index,:]\n",
    "train_edges_false = X_neg[train_index,:]\n",
    "val_edges = X_pos[train_index,:]\n",
    "val_edges_false = X_neg[train_index,:]\n",
    "test_edges = X_pos[test_index,:]\n",
    "test_edges_false = X_neg[test_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(train_edges).to_csv(\"/Users/kk3671/Documents/Op÷enNE/data/yeast/train_links_0.5_split_1.txt\", index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(test_edges).to_csv(\"/Users/kk3671/Documents/OpenNE/data/yeast/train_links_0.5_split_2.txt\", index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.concatenate([train_edges, train_edges_false])\n",
    "test_data =  np.concatenate([test_edges, test_edges_false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_data).to_csv(\"/Users/kk3671/Documents/OpenNE/data/yeast/train_data_1.txt\", index=False, header=False, sep=' ')\n",
    "pd.DataFrame(test_data).to_csv(\"/Users/kk3671/Documents/OpenNE/data/yeast/train_data_2.txt\", index=False, header=False, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/Users/kk3671/Documents/OpenNE/data/yeast/train_data_1.txt\", header=None, sep=' ')\n",
    "test_data = pd.read_csv(\"/Users/kk3671/Documents/OpenNE/data/yeast/train_data_2.txt\",  header=None, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_edges = train_data.loc[train_data.iloc[:,2]==1].values\n",
    "train_edges_false = train_data.loc[train_data.iloc[:,2]==0].values\n",
    "val_edges = train_data.loc[train_data.iloc[:,2]==1].values\n",
    "val_edges_false = train_data.loc[train_data.iloc[:,2]==0].values\n",
    "test_edges = test_data.loc[test_data.iloc[:,2]==1].values\n",
    "test_edges_false = test_data.loc[test_data.iloc[:,2]==0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_edges =  np.concatenate([val_edges, val_edges_false])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1_rows = set(map(tuple, train_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2_rows = set(map(tuple, test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_rows.isdisjoint(a2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_file = path + 'expression_data.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from convertdata import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train test and validation_split\n"
     ]
    }
   ],
   "source": [
    "dataset = create_train_test_split(path, adj, test_size=0.1, validation_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edges = dataset['train_pos']\n",
    "train_edges_false = dataset['train_neg']\n",
    "val_edges = dataset['val_pos']\n",
    "val_edges_false = dataset['val_neg']\n",
    "test_edges = dataset['test_pos']\n",
    "test_edges_false = dataset['test_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 5950\n",
      "Total edges: 544652.0\n",
      "Training edges (positive): 395875\n",
      "Training edges (negative): 395875\n",
      "Validation edges (positive): 43987\n",
      "Validation edges (negative): 43987\n",
      "Test edges (positive): 48874\n",
      "Test edges (negative): 48874\n"
     ]
    }
   ],
   "source": [
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", adj.shape[0])\n",
    "print(\"Total edges:\", np.sum(adj))  # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print(\"Training edges (positive):\", len(train_edges))\n",
    "print(\"Training edges (negative):\", len(train_edges_false))\n",
    "print(\"Validation edges (positive):\", len(val_edges))\n",
    "print(\"Validation edges (negative):\", len(val_edges_false))\n",
    "print(\"Test edges (positive):\", len(test_edges))\n",
    "print(\"Test edges (negative):\", len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_edges =  np.concatenate([val_edges, val_edges_false])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Nodes\n",
      "attr_M: 536\n",
      "id_N: 5950\n",
      "Reading training links\n",
      "Constructing Neighborhood maps\n",
      "Constructing train data\n"
     ]
    }
   ],
   "source": [
    "Data = data.LoadData(path, train_links=train_edges, features_file=feature_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791750"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data.links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48874"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87974"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'attr_embedding_size': 128,\n",
       " 'batch_size': 256,\n",
       " 'epoch': 20,\n",
       " 'id_embedding_size': 128,\n",
       " 'learning_rate': 0.005,\n",
       " 'n_neg_samples': 10,\n",
       " 'representation_size': 128}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {}\n",
    "parameters['id_embedding_size'] = 128\n",
    "parameters['attr_embedding_size'] = 128\n",
    "parameters['batch_size'] = 256\n",
    "parameters['alpha'] = 0\n",
    "parameters['n_neg_samples'] = 10\n",
    "parameters['epoch'] = 20\n",
    "parameters['representation_size'] = 128\n",
    "parameters['learning_rate'] = 0.005\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id_embedding_size': 128, 'attr_embedding_size': 128, 'batch_size': 256, 'alpha': 0, 'n_neg_samples': 10, 'epoch': 20, 'representation_size': 128, 'learning_rate': 0.005}\n",
      "Using structure and attribute embedding\n",
      "Epoch:      1, Train-Batch Loss: 6.310084483, Validation AUC: 0.557508353 *\n",
      "Epoch:      2, Train-Batch Loss: 1.949577686, Validation AUC: 0.563390622 *\n",
      "Epoch:      3, Train-Batch Loss: 1.582844538, Validation AUC: 0.590562869 *\n",
      "Epoch:      4, Train-Batch Loss: 1.516007597, Validation AUC: 0.638523756 *\n",
      "Epoch:      5, Train-Batch Loss: 1.492391334, Validation AUC: 0.685045378 *\n",
      "Epoch:      6, Train-Batch Loss: 1.433447374, Validation AUC: 0.718403083 *\n",
      "Epoch:      7, Train-Batch Loss: 1.402797732, Validation AUC: 0.738265165 *\n",
      "Epoch:      8, Train-Batch Loss: 1.371006530, Validation AUC: 0.750990422 *\n",
      "Epoch:      9, Train-Batch Loss: 1.387766419, Validation AUC: 0.758661669 *\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kk3671/Documents/GNE_bk/evaluation.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     10, Train-Batch Loss: 1.355640317, Validation AUC: 0.762884010 *\n",
      "Epoch:     11, Train-Batch Loss: 1.360708615, Validation AUC: 0.763946740 *\n",
      "Epoch:     12, Train-Batch Loss: 1.364342529, Validation AUC: 0.761929607 \n",
      "Epoch:     13, Train-Batch Loss: 1.342732669, Validation AUC: 0.759919975 \n",
      "Epoch:     14, Train-Batch Loss: 1.312292517, Validation AUC: 0.757366515 \n",
      "No improvement found in a while, stopping optimization.\n",
      "{'id_embedding_size': 128, 'attr_embedding_size': 128, 'batch_size': 256, 'alpha': 1, 'n_neg_samples': 10, 'epoch': 20, 'representation_size': 128, 'learning_rate': 0.005}\n",
      "Using structure and attribute embedding\n",
      "Epoch:      1, Train-Batch Loss: 7.703314566, Validation AUC: 0.666438791 *\n",
      "Epoch:      2, Train-Batch Loss: 4.920528603, Validation AUC: 0.707863075 *\n",
      "Epoch:      3, Train-Batch Loss: 2.679996250, Validation AUC: 0.746812381 *\n",
      "Epoch:      4, Train-Batch Loss: 1.687004831, Validation AUC: 0.757842852 *\n",
      "Epoch:      5, Train-Batch Loss: 1.603077887, Validation AUC: 0.771933069 *\n",
      "Epoch:      6, Train-Batch Loss: 1.536834433, Validation AUC: 0.784443413 *\n",
      "Epoch:      7, Train-Batch Loss: 1.512389474, Validation AUC: 0.791403814 *\n",
      "Epoch:      8, Train-Batch Loss: 1.481894891, Validation AUC: 0.795784212 *\n",
      "Epoch:      9, Train-Batch Loss: 1.506677415, Validation AUC: 0.795106782 \n",
      "Epoch:     10, Train-Batch Loss: 1.478902300, Validation AUC: 0.791101561 \n",
      "Epoch:     11, Train-Batch Loss: 1.488173666, Validation AUC: 0.783946980 \n",
      "No improvement found in a while, stopping optimization.\n"
     ]
    }
   ],
   "source": [
    "for i in [0,1]:\n",
    "    parameters['alpha'] = i\n",
    "    model = GNE(path, Data, 2018, parameters)\n",
    "    embeddings = model.train(validation_edges, val_edge_labels)\n",
    "    pd.DataFrame(embeddings).to_csv(\"embeddings_yeast_alpha_\"+str(parameters['alpha'])+\".txt\", header=False, index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_1 = pd.read_csv(\"embeddings_yeast_alpha_0.txt\", header=None, sep=\",\")\n",
    "embeddings_2 = pd.read_csv(\"embeddings_yeast_alpha_1.txt\", header=None, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_1 = embeddings_1.values\n",
    "embeddings_2 = embeddings_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(embeddings_1, train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(embeddings_1, train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "edge_classifier_1 = LogisticRegression(random_state=0)\n",
    "edge_classifier_1.fit(train_edge_embs, train_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_preds = edge_classifier.predict_proba(test_edge_embs)[:, 1]\n",
    "# test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "# test_ap = average_precision_score(test_edge_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('GNE Test ROC score: ', str(test_roc))\n",
    "# print('GNE Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(embeddings_2, train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(embeddings_2, train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "edge_classifier_2 = LogisticRegression(random_state=0)\n",
    "edge_classifier_2.fit(train_edge_embs, train_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ecoli\n",
    "#GNE Test ROC score:  0.940158504921\n",
    "#GNE Test AP score:  0.93897040116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# yeast\n",
    "# GNE Test ROC score:  0.821812518988\n",
    "# GNE Test AP score:  0.80728890868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data = pd.read_csv(\"/Users/kk3671/Documents/GNE/data/yeast/evaluation_data.txt\", header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_edges = evaluation_data.iloc[:,:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = evaluation_data.loc[evaluation_data.iloc[:,2]==1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.permutation(test_edges_false.shape[0])[:test_pos.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_neg = test_edges_false[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_edges_data = np.concatenate([test_pos.values,test_edges_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_edge_labels = np.concatenate([np.ones(len(test_pos)), np.zeros(len(test_edges_neg))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_edge_embs = get_edge_embeddings(embeddings, test_edges_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_edge_labels = evaluation_data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNE Test ROC score:  0.701490073054\n",
      "GNE Test AP score:  0.685019702035\n"
     ]
    }
   ],
   "source": [
    "test_preds = edge_classifier_1.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds)\n",
    "print('GNE Test ROC score: ', str(test_roc))\n",
    "print('GNE Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNE Test ROC score:  0.714396129958\n",
      "GNE Test AP score:  0.690655808085\n"
     ]
    }
   ],
   "source": [
    "test_preds_all = edge_classifier_2.predict_proba(test_edge_embs)[:, 1]\n",
    "test_roc = roc_auc_score(test_edge_labels, test_preds_all)\n",
    "test_ap = average_precision_score(test_edge_labels, test_preds_all)\n",
    "print('GNE Test ROC score: ', str(test_roc))\n",
    "print('GNE Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# structure\n",
    "# CNE Test ROC score:  0.6852121037\n",
    "# GNE Test AP score:  0.676090762932\n",
    "# all\n",
    "# GNE Test ROC score:  0.707318321648\n",
    "# GNE Test AP score:  0.679146387378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['structure'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['all'] = test_preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>structure</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3844</td>\n",
       "      <td>5174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.690379</td>\n",
       "      <td>0.705964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1275</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189159</td>\n",
       "      <td>0.104340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1824</td>\n",
       "      <td>5545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361572</td>\n",
       "      <td>0.626138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3143</td>\n",
       "      <td>4530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500160</td>\n",
       "      <td>0.488627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2100</td>\n",
       "      <td>3020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506807</td>\n",
       "      <td>0.771675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4350</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334140</td>\n",
       "      <td>0.308406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>4854</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682290</td>\n",
       "      <td>0.726682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1702</td>\n",
       "      <td>3752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542675</td>\n",
       "      <td>0.831660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4116</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595382</td>\n",
       "      <td>0.679016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1225</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.359938</td>\n",
       "      <td>0.485050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5222</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506546</td>\n",
       "      <td>0.475394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1937</td>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>0.376084</td>\n",
       "      <td>0.390902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>409</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144267</td>\n",
       "      <td>0.086058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5326</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392981</td>\n",
       "      <td>0.438745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3266</td>\n",
       "      <td>3473</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>0.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1237</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402819</td>\n",
       "      <td>0.258122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1310</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352605</td>\n",
       "      <td>0.233673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5589</td>\n",
       "      <td>2661</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.639261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>98</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>0.333033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>665</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>0.097311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4910</td>\n",
       "      <td>2976</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451166</td>\n",
       "      <td>0.297100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4055</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325566</td>\n",
       "      <td>0.292459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4714</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.598349</td>\n",
       "      <td>0.800520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>316</td>\n",
       "      <td>3094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320886</td>\n",
       "      <td>0.371509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5140</td>\n",
       "      <td>2795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740637</td>\n",
       "      <td>0.861345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>254</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244618</td>\n",
       "      <td>0.251898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4433</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125231</td>\n",
       "      <td>0.188131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>276</td>\n",
       "      <td>2124</td>\n",
       "      <td>1</td>\n",
       "      <td>0.592363</td>\n",
       "      <td>0.728491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3689</td>\n",
       "      <td>791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481178</td>\n",
       "      <td>0.706937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5186</td>\n",
       "      <td>535</td>\n",
       "      <td>1</td>\n",
       "      <td>0.879430</td>\n",
       "      <td>0.939686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12805</th>\n",
       "      <td>2654</td>\n",
       "      <td>2070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.710706</td>\n",
       "      <td>0.889205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>2867</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730996</td>\n",
       "      <td>0.831099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>3950</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751989</td>\n",
       "      <td>0.886380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>3950</td>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522448</td>\n",
       "      <td>0.682868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>3344</td>\n",
       "      <td>3345</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584260</td>\n",
       "      <td>0.370769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>3117</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>0.223870</td>\n",
       "      <td>0.157122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12811</th>\n",
       "      <td>396</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533179</td>\n",
       "      <td>0.604227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12812</th>\n",
       "      <td>3960</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.190993</td>\n",
       "      <td>0.138038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>2194</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>0.425917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12814</th>\n",
       "      <td>3616</td>\n",
       "      <td>3020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277202</td>\n",
       "      <td>0.497197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12815</th>\n",
       "      <td>3737</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228253</td>\n",
       "      <td>0.250421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12816</th>\n",
       "      <td>2270</td>\n",
       "      <td>4533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263631</td>\n",
       "      <td>0.412860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12817</th>\n",
       "      <td>1648</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.319392</td>\n",
       "      <td>0.305993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12818</th>\n",
       "      <td>995</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310231</td>\n",
       "      <td>0.421840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12819</th>\n",
       "      <td>44</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472140</td>\n",
       "      <td>0.465391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>5798</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.291637</td>\n",
       "      <td>0.259367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>2827</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>0.535538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12822</th>\n",
       "      <td>5751</td>\n",
       "      <td>5174</td>\n",
       "      <td>1</td>\n",
       "      <td>0.242865</td>\n",
       "      <td>0.162225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12823</th>\n",
       "      <td>2977</td>\n",
       "      <td>5545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737464</td>\n",
       "      <td>0.921161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12824</th>\n",
       "      <td>1843</td>\n",
       "      <td>2243</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.496378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>5337</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145837</td>\n",
       "      <td>0.107250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12826</th>\n",
       "      <td>4948</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654635</td>\n",
       "      <td>0.710845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>4375</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380074</td>\n",
       "      <td>0.477499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>4574</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757195</td>\n",
       "      <td>0.657929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>303</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.339761</td>\n",
       "      <td>0.259817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>2110</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551665</td>\n",
       "      <td>0.629546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>257</td>\n",
       "      <td>4985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709428</td>\n",
       "      <td>0.863960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>2473</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.397493</td>\n",
       "      <td>0.266426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>5428</td>\n",
       "      <td>3689</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702096</td>\n",
       "      <td>0.937554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>3360</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340448</td>\n",
       "      <td>0.535582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12835 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1  2  structure       all\n",
       "0      3844  5174  1   0.690379  0.705964\n",
       "1      1275  2873  1   0.189159  0.104340\n",
       "2      1824  5545  1   0.361572  0.626138\n",
       "3      3143  4530  1   0.500160  0.488627\n",
       "4      2100  3020  1   0.506807  0.771675\n",
       "5      4350  2873  1   0.334140  0.308406\n",
       "6        39  4854  1   0.682290  0.726682\n",
       "7      1702  3752  1   0.542675  0.831660\n",
       "8      4116   164  1   0.595382  0.679016\n",
       "9      1225   179  1   0.359938  0.485050\n",
       "10     5222  2873  1   0.506546  0.475394\n",
       "11     1937   792  1   0.376084  0.390902\n",
       "12      409   735  1   0.144267  0.086058\n",
       "13     5326   179  1   0.392981  0.438745\n",
       "14     3266  3473  1   0.894500  0.991000\n",
       "15     1237   735  1   0.402819  0.258122\n",
       "16     1310   735  1   0.352605  0.233673\n",
       "17     5589  2661  1   0.605300  0.639261\n",
       "18       98  2873  1   0.505014  0.333033\n",
       "19      665   179  1   0.181309  0.097311\n",
       "20     4910  2976  1   0.451166  0.297100\n",
       "21     4055   179  1   0.325566  0.292459\n",
       "22     4714    26  1   0.598349  0.800520\n",
       "23      316  3094  1   0.320886  0.371509\n",
       "24     5140  2795  1   0.740637  0.861345\n",
       "25      254    26  1   0.244618  0.251898\n",
       "26     4433   179  1   0.125231  0.188131\n",
       "27      276  2124  1   0.592363  0.728491\n",
       "28     3689   791  1   0.481178  0.706937\n",
       "29     5186   535  1   0.879430  0.939686\n",
       "...     ...   ... ..        ...       ...\n",
       "12805  2654  2070  1   0.710706  0.889205\n",
       "12806  2867   179  1   0.730996  0.831099\n",
       "12807  3950   215  1   0.751989  0.886380\n",
       "12808  3950  2532  1   0.522448  0.682868\n",
       "12809  3344  3345  1   0.584260  0.370769\n",
       "12810  3117   360  1   0.223870  0.157122\n",
       "12811   396   258  1   0.533179  0.604227\n",
       "12812  3960   179  1   0.190993  0.138038\n",
       "12813  2194   735  1   0.440952  0.425917\n",
       "12814  3616  3020  1   0.277202  0.497197\n",
       "12815  3737    39  1   0.228253  0.250421\n",
       "12816  2270  4533  1   0.263631  0.412860\n",
       "12817  1648   735  1   0.319392  0.305993\n",
       "12818   995   735  1   0.310231  0.421840\n",
       "12819    44   735  1   0.472140  0.465391\n",
       "12820  5798  2873  1   0.291637  0.259367\n",
       "12821  2827   179  1   0.404298  0.535538\n",
       "12822  5751  5174  1   0.242865  0.162225\n",
       "12823  2977  5545  1   0.737464  0.921161\n",
       "12824  1843  2243  1   0.239002  0.496378\n",
       "12825  5337   179  1   0.145837  0.107250\n",
       "12826  4948   179  1   0.654635  0.710845\n",
       "12827  4375   179  1   0.380074  0.477499\n",
       "12828  4574   179  1   0.757195  0.657929\n",
       "12829   303   179  1   0.339761  0.259817\n",
       "12830  2110   735  1   0.551665  0.629546\n",
       "12831   257  4985  1   0.709428  0.863960\n",
       "12832  2473  2873  1   0.397493  0.266426\n",
       "12833  5428  3689  1   0.702096  0.937554\n",
       "12834  3360   179  1   0.340448  0.535582\n",
       "\n",
       "[12835 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_true = predictions.loc[predictions.iloc[:,2]==1]\n",
    "predictions_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict÷ions_bk =predictions.copy("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions = predictions_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Structure only\n",
    "# GNE Test ROC score:  0.779685103723\n",
    "# GNE Test AP score:  0.781139913429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all only\n",
    "# GNE Test ROC score:  0.827404280591\n",
    "# GNE Test AP score:  0.824513278629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['structure_rank'] = predictions['structure'].rank(ascending=False, method=\"dense\")\n",
    "predictions['all_rank'] = predictions['all'].rank(ascending=False, method=\"dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "improved_predictions = predictions.loc[ (predictions.loc[:,'structure']<=predictions.loc[:,'all'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kk3671/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "improved_predictions['diff'] = predictions.loc[:,'all'] - predictions.loc[:,'structure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10363891807634915"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(improved_predictions['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_predictions = improved_predictions.loc[improved_predictions.loc[:,2]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>structure</th>\n",
       "      <th>all</th>\n",
       "      <th>structure_rank</th>\n",
       "      <th>all_rank</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>2615</td>\n",
       "      <td>1799</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310224</td>\n",
       "      <td>0.858648</td>\n",
       "      <td>15685.0</td>\n",
       "      <td>1796.0</td>\n",
       "      <td>0.548424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11542</th>\n",
       "      <td>3630</td>\n",
       "      <td>5545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.257449</td>\n",
       "      <td>0.754420</td>\n",
       "      <td>18306.0</td>\n",
       "      <td>3790.0</td>\n",
       "      <td>0.496972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>1000</td>\n",
       "      <td>5444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254082</td>\n",
       "      <td>0.718622</td>\n",
       "      <td>18474.0</td>\n",
       "      <td>4467.0</td>\n",
       "      <td>0.464540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>1958</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349644</td>\n",
       "      <td>0.808827</td>\n",
       "      <td>13784.0</td>\n",
       "      <td>2715.0</td>\n",
       "      <td>0.459183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>5205</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315456</td>\n",
       "      <td>0.773419</td>\n",
       "      <td>15453.0</td>\n",
       "      <td>3397.0</td>\n",
       "      <td>0.457963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1227</td>\n",
       "      <td>4533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375480</td>\n",
       "      <td>0.817411</td>\n",
       "      <td>12599.0</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>0.441931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6385</th>\n",
       "      <td>878</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.440086</td>\n",
       "      <td>0.877601</td>\n",
       "      <td>9960.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>0.437515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>4012</td>\n",
       "      <td>4291</td>\n",
       "      <td>1</td>\n",
       "      <td>0.391820</td>\n",
       "      <td>0.826919</td>\n",
       "      <td>11897.0</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>0.435099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>1092</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.421663</td>\n",
       "      <td>0.855643</td>\n",
       "      <td>10657.0</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>0.433980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>4825</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.453174</td>\n",
       "      <td>0.885383</td>\n",
       "      <td>9481.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>0.432209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>3050</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.313975</td>\n",
       "      <td>0.745459</td>\n",
       "      <td>15519.0</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>0.431484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>5186</td>\n",
       "      <td>2532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399719</td>\n",
       "      <td>0.830513</td>\n",
       "      <td>11555.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>0.430794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>4750</td>\n",
       "      <td>765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197801</td>\n",
       "      <td>0.617503</td>\n",
       "      <td>21326.0</td>\n",
       "      <td>6479.0</td>\n",
       "      <td>0.419702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100</th>\n",
       "      <td>765</td>\n",
       "      <td>4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197801</td>\n",
       "      <td>0.617503</td>\n",
       "      <td>21326.0</td>\n",
       "      <td>6479.0</td>\n",
       "      <td>0.419702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>4896</td>\n",
       "      <td>5545</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253111</td>\n",
       "      <td>0.668365</td>\n",
       "      <td>18526.0</td>\n",
       "      <td>5446.0</td>\n",
       "      <td>0.415254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>2627</td>\n",
       "      <td>1408</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497938</td>\n",
       "      <td>0.911253</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>893.0</td>\n",
       "      <td>0.413316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>2314</td>\n",
       "      <td>5300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301755</td>\n",
       "      <td>0.713334</td>\n",
       "      <td>16099.0</td>\n",
       "      <td>4566.0</td>\n",
       "      <td>0.411580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>2103</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407924</td>\n",
       "      <td>0.819321</td>\n",
       "      <td>11211.0</td>\n",
       "      <td>2527.0</td>\n",
       "      <td>0.411397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>5428</td>\n",
       "      <td>1523</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361755</td>\n",
       "      <td>0.769786</td>\n",
       "      <td>13226.0</td>\n",
       "      <td>3483.0</td>\n",
       "      <td>0.408031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>5296</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296018</td>\n",
       "      <td>0.703865</td>\n",
       "      <td>16386.0</td>\n",
       "      <td>4749.0</td>\n",
       "      <td>0.407847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>3314</td>\n",
       "      <td>4953</td>\n",
       "      <td>1</td>\n",
       "      <td>0.466101</td>\n",
       "      <td>0.872978</td>\n",
       "      <td>9018.0</td>\n",
       "      <td>1517.0</td>\n",
       "      <td>0.406876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>3547</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430101</td>\n",
       "      <td>0.834513</td>\n",
       "      <td>10324.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>0.404412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>5470</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524743</td>\n",
       "      <td>0.927855</td>\n",
       "      <td>7048.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>0.403112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>4070</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.360208</td>\n",
       "      <td>0.759616</td>\n",
       "      <td>13283.0</td>\n",
       "      <td>3686.0</td>\n",
       "      <td>0.399408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>1245</td>\n",
       "      <td>3689</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294940</td>\n",
       "      <td>0.692519</td>\n",
       "      <td>16431.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>0.397579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>4627</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292426</td>\n",
       "      <td>0.689487</td>\n",
       "      <td>16538.0</td>\n",
       "      <td>5001.0</td>\n",
       "      <td>0.397061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>2314</td>\n",
       "      <td>3442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278345</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>17264.0</td>\n",
       "      <td>5384.0</td>\n",
       "      <td>0.392995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>4024</td>\n",
       "      <td>1096</td>\n",
       "      <td>1</td>\n",
       "      <td>0.259789</td>\n",
       "      <td>0.651751</td>\n",
       "      <td>18195.0</td>\n",
       "      <td>5774.0</td>\n",
       "      <td>0.391962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>4934</td>\n",
       "      <td>1096</td>\n",
       "      <td>1</td>\n",
       "      <td>0.483006</td>\n",
       "      <td>0.874235</td>\n",
       "      <td>8406.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>0.391229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10483</th>\n",
       "      <td>2820</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478013</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>8573.0</td>\n",
       "      <td>1581.0</td>\n",
       "      <td>0.391065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>1328</td>\n",
       "      <td>4530</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686770</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>5043.0</td>\n",
       "      <td>0.000987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9792</th>\n",
       "      <td>2923</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350874</td>\n",
       "      <td>0.351842</td>\n",
       "      <td>13726.0</td>\n",
       "      <td>13466.0</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245835</td>\n",
       "      <td>0.246800</td>\n",
       "      <td>18904.0</td>\n",
       "      <td>17320.0</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>281</td>\n",
       "      <td>3816</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548423</td>\n",
       "      <td>0.549327</td>\n",
       "      <td>6328.0</td>\n",
       "      <td>8026.0</td>\n",
       "      <td>0.000904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>1505</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.631258</td>\n",
       "      <td>0.632123</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>6183.0</td>\n",
       "      <td>0.000865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>4483</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419185</td>\n",
       "      <td>0.420014</td>\n",
       "      <td>10765.0</td>\n",
       "      <td>11383.0</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10117</th>\n",
       "      <td>3772</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384942</td>\n",
       "      <td>0.385749</td>\n",
       "      <td>12177.0</td>\n",
       "      <td>12410.0</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>3473</td>\n",
       "      <td>5249</td>\n",
       "      <td>1</td>\n",
       "      <td>0.953505</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>31.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>256</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621680</td>\n",
       "      <td>0.622429</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>6381.0</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>5603</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753768</td>\n",
       "      <td>0.754488</td>\n",
       "      <td>1737.0</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>0.000720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7358</th>\n",
       "      <td>3068</td>\n",
       "      <td>305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378966</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>12452.0</td>\n",
       "      <td>12581.0</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>324</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.387799</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>12350.0</td>\n",
       "      <td>0.000699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6236</th>\n",
       "      <td>5215</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.421478</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>10665.0</td>\n",
       "      <td>11318.0</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5767</th>\n",
       "      <td>3039</td>\n",
       "      <td>2976</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347156</td>\n",
       "      <td>0.347824</td>\n",
       "      <td>13908.0</td>\n",
       "      <td>13616.0</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>305</td>\n",
       "      <td>3864</td>\n",
       "      <td>1</td>\n",
       "      <td>0.278209</td>\n",
       "      <td>0.278849</td>\n",
       "      <td>17268.0</td>\n",
       "      <td>16003.0</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>4740</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.143004</td>\n",
       "      <td>0.143597</td>\n",
       "      <td>23786.0</td>\n",
       "      <td>22079.0</td>\n",
       "      <td>0.000593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8191</th>\n",
       "      <td>3251</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.422634</td>\n",
       "      <td>0.423222</td>\n",
       "      <td>10610.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>3935</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.365550</td>\n",
       "      <td>0.366134</td>\n",
       "      <td>13042.0</td>\n",
       "      <td>12988.0</td>\n",
       "      <td>0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10711</th>\n",
       "      <td>3534</td>\n",
       "      <td>4649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.406047</td>\n",
       "      <td>0.406607</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11792.0</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>2414</td>\n",
       "      <td>5456</td>\n",
       "      <td>1</td>\n",
       "      <td>0.861401</td>\n",
       "      <td>0.861921</td>\n",
       "      <td>468.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1961</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117976</td>\n",
       "      <td>0.118456</td>\n",
       "      <td>24602.0</td>\n",
       "      <td>23250.0</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>343</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.104939</td>\n",
       "      <td>24938.0</td>\n",
       "      <td>23828.0</td>\n",
       "      <td>0.000399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11692</th>\n",
       "      <td>1040</td>\n",
       "      <td>2795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.229572</td>\n",
       "      <td>0.229951</td>\n",
       "      <td>19746.0</td>\n",
       "      <td>18029.0</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>2056</td>\n",
       "      <td>3307</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.201076</td>\n",
       "      <td>21181.0</td>\n",
       "      <td>19330.0</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6908</th>\n",
       "      <td>2604</td>\n",
       "      <td>2873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261004</td>\n",
       "      <td>0.261256</td>\n",
       "      <td>18150.0</td>\n",
       "      <td>16717.0</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10159</th>\n",
       "      <td>2260</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.315761</td>\n",
       "      <td>0.315989</td>\n",
       "      <td>15434.0</td>\n",
       "      <td>14628.0</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1539</td>\n",
       "      <td>3953</td>\n",
       "      <td>1</td>\n",
       "      <td>0.325499</td>\n",
       "      <td>0.325659</td>\n",
       "      <td>14917.0</td>\n",
       "      <td>14288.0</td>\n",
       "      <td>0.000159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1941</td>\n",
       "      <td>1887</td>\n",
       "      <td>1</td>\n",
       "      <td>0.805770</td>\n",
       "      <td>0.805885</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>2769.0</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>653</td>\n",
       "      <td>4598</td>\n",
       "      <td>1</td>\n",
       "      <td>0.418767</td>\n",
       "      <td>0.418821</td>\n",
       "      <td>10784.0</td>\n",
       "      <td>11420.0</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11027</th>\n",
       "      <td>1331</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347790</td>\n",
       "      <td>0.347802</td>\n",
       "      <td>13874.0</td>\n",
       "      <td>13617.0</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1  2  structure       all  structure_rank  all_rank      diff\n",
       "1043   2615  1799  1   0.310224  0.858648         15685.0    1796.0  0.548424\n",
       "11542  3630  5545  1   0.257449  0.754420         18306.0    3790.0  0.496972\n",
       "9045   1000  5444  1   0.254082  0.718622         18474.0    4467.0  0.464540\n",
       "2800   1958   735  1   0.349644  0.808827         13784.0    2715.0  0.459183\n",
       "1948   5205   735  1   0.315456  0.773419         15453.0    3397.0  0.457963\n",
       "796    1227  4533  1   0.375480  0.817411         12599.0    2562.0  0.441931\n",
       "6385    878   735  1   0.440086  0.877601          9960.0    1450.0  0.437515\n",
       "1748   4012  4291  1   0.391820  0.826919         11897.0    2375.0  0.435099\n",
       "12495  1092   735  1   0.421663  0.855643         10657.0    1836.0  0.433980\n",
       "3091   4825   735  1   0.453174  0.885383          9481.0    1298.0  0.432209\n",
       "9132   3050   735  1   0.313975  0.745459         15519.0    3968.0  0.431484\n",
       "5651   5186  2532  1   0.399719  0.830513         11555.0    2307.0  0.430794\n",
       "6058   4750   765  1   0.197801  0.617503         21326.0    6479.0  0.419702\n",
       "11100   765  4750  1   0.197801  0.617503         21326.0    6479.0  0.419702\n",
       "7613   4896  5545  1   0.253111  0.668365         18526.0    5446.0  0.415254\n",
       "7944   2627  1408  1   0.497938  0.911253          7910.0     893.0  0.413316\n",
       "5881   2314  5300  1   0.301755  0.713334         16099.0    4566.0  0.411580\n",
       "3286   2103   735  1   0.407924  0.819321         11211.0    2527.0  0.411397\n",
       "416    5428  1523  1   0.361755  0.769786         13226.0    3483.0  0.408031\n",
       "1502   5296   735  1   0.296018  0.703865         16386.0    4749.0  0.407847\n",
       "3184   3314  4953  1   0.466101  0.872978          9018.0    1517.0  0.406876\n",
       "8626   3547   735  1   0.430101  0.834513         10324.0    2228.0  0.404412\n",
       "11202  5470   735  1   0.524743  0.927855          7048.0     662.0  0.403112\n",
       "281    4070   735  1   0.360208  0.759616         13283.0    3686.0  0.399408\n",
       "10086  1245  3689  1   0.294940  0.692519         16431.0    4935.0  0.397579\n",
       "7311   4627   735  1   0.292426  0.689487         16538.0    5001.0  0.397061\n",
       "5272   2314  3442  1   0.278345  0.671340         17264.0    5384.0  0.392995\n",
       "12035  4024  1096  1   0.259789  0.651751         18195.0    5774.0  0.391962\n",
       "5616   4934  1096  1   0.483006  0.874235          8406.0    1499.0  0.391229\n",
       "10483  2820   735  1   0.478013  0.869077          8573.0    1581.0  0.391065\n",
       "...     ...   ... ..        ...       ...             ...       ...       ...\n",
       "12740  1328  4530  1   0.686770  0.687756          2919.0    5043.0  0.000987\n",
       "9792   2923   735  1   0.350874  0.351842         13726.0   13466.0  0.000968\n",
       "5752      1   179  1   0.245835  0.246800         18904.0   17320.0  0.000966\n",
       "12291   281  3816  1   0.548423  0.549327          6328.0    8026.0  0.000904\n",
       "3353   1505   179  1   0.631258  0.632123          4095.0    6183.0  0.000865\n",
       "976    4483   179  1   0.419185  0.420014         10765.0   11383.0  0.000828\n",
       "10117  3772   735  1   0.384942  0.385749         12177.0   12410.0  0.000808\n",
       "11306  3473  5249  1   0.953505  0.954286            31.0     329.0  0.000780\n",
       "1630    256   735  1   0.621680  0.622429          4329.0    6381.0  0.000749\n",
       "6006   5603   179  1   0.753768  0.754488          1737.0    3787.0  0.000720\n",
       "7358   3068   305  1   0.378966  0.379673         12452.0   12581.0  0.000707\n",
       "619     324   735  1   0.387100  0.387799         12100.0   12350.0  0.000699\n",
       "6236   5215   179  1   0.421478  0.422173         10665.0   11318.0  0.000695\n",
       "5767   3039  2976  1   0.347156  0.347824         13908.0   13616.0  0.000669\n",
       "6774    305  3864  1   0.278209  0.278849         17268.0   16003.0  0.000640\n",
       "1166   4740   735  1   0.143004  0.143597         23786.0   22079.0  0.000593\n",
       "8191   3251  2873  1   0.422634  0.423222         10610.0   11289.0  0.000588\n",
       "8388   3935   735  1   0.365550  0.366134         13042.0   12988.0  0.000583\n",
       "10711  3534  4649  1   0.406047  0.406607         11287.0   11792.0  0.000560\n",
       "4868   2414  5456  1   0.861401  0.861921           468.0    1730.0  0.000520\n",
       "4955   1961   179  1   0.117976  0.118456         24602.0   23250.0  0.000479\n",
       "4681    343   735  1   0.104539  0.104939         24938.0   23828.0  0.000399\n",
       "11692  1040  2795  1   0.229572  0.229951         19746.0   18029.0  0.000379\n",
       "11721  2056  3307  1   0.200774  0.201076         21181.0   19330.0  0.000303\n",
       "6908   2604  2873  1   0.261004  0.261256         18150.0   16717.0  0.000251\n",
       "10159  2260   164  1   0.315761  0.315989         15434.0   14628.0  0.000228\n",
       "1344   1539  3953  1   0.325499  0.325659         14917.0   14288.0  0.000159\n",
       "1814   1941  1887  1   0.805770  0.805885          1006.0    2769.0  0.000115\n",
       "3984    653  4598  1   0.418767  0.418821         10784.0   11420.0  0.000054\n",
       "11027  1331   179  1   0.347790  0.347802         13874.0   13617.0  0.000012\n",
       "\n",
       "[8120 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_predictions.sort_values(['diff'], ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "improved_predictions.to_csv(\"../Gene-Network-Embedding/data/yeast/improved_predictions_latest.txt\", index=False, header=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Tahoma']\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAESCAYAAADqoDJEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZjA1wCa4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c071828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r\"Recall\", fontsize=18)\n",
    "# ax.axhline(y=0.839)\n",
    "ax.set_ylabel(\"Precision\", fontsize=18)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(test_edge_labels, test_preds)\n",
    "\n",
    "ax.plot(recall, precision, color='b', alpha=1, label =\"Precision-Recall curve: area={0:0.2f}\".format(test_ap))\n",
    "ax.legend(fontsize='x-large')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.savefig('yeast_pr_curve.eps', dpi =1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_precision_recall_curve(test_labels, edge_classifier.predict_proba(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_edges.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['predicted'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['predicted'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"../Gene-Network-Embedding/data/yeast/predictions.txt\", index=False, header=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_roc = roc_auc_score(df.iloc[:,2], df.iloc[:,3])\n",
    "test_ap = average_precision_score(df.iloc[:,2], df.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GNE Test ROC score: ', str(test_roc))\n",
    "print('GNE Test AP score: ', str(test_ap))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
