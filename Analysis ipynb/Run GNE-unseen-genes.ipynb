{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "import LoadData as data\n",
    "import numpy as np\n",
    "from GNE import GNE\n",
    "from evaluation import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './data/ecoli/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Loading [./data/ecoli/edgelist_biogrid.txt]...\n"
     ]
    }
   ],
   "source": [
    "geneids = pd.read_csv(path + \"gene_ids.tsv\", sep=\" \")\n",
    "num_genes = geneids.shape[0]\n",
    "link_file = path + \"edgelist_biogrid.txt\"\n",
    "\n",
    "adj = load_network(link_file, num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148340.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_generalization(adj, validation_size = None, gene_split=None):\n",
    "    # Split link information to train and validation with test split size\n",
    "    edgelist = convertAdjMatrixToSortedRankTSV(adj)\n",
    "    geneids = edgelist.iloc[:, :2]\n",
    "    col1 = np.array(geneids).min(axis=1).astype(int)\n",
    "    col2 = np.array(geneids).max(axis=1).astype(int)\n",
    "    col3 = np.array(edgelist.iloc[:, 2])\n",
    "    if gene_split != None:\n",
    "        col1 = col1 + gene_split\n",
    "        col2 = col2 + gene_split\n",
    "    data_df = pd.DataFrame()\n",
    "    data_df['i'] = col1\n",
    "    data_df['j'] = col2\n",
    "    data_df['k'] = col3\n",
    "    data_df = data_df.drop_duplicates()\n",
    "\n",
    "    train_edges = data_df.loc[data_df.iloc[:, 2] == 1].values\n",
    "    neg_edgelist = data_df.loc[data_df.iloc[:, 2] == 0]\n",
    "    ind = random.sample(range(len(neg_edgelist)), train_edges.shape[0])\n",
    "    neg_edges = pd.DataFrame(np.random.permutation(neg_edgelist.values))\n",
    "    train_edges_false = neg_edges.iloc[ind, :].values\n",
    "    dataset = {}\n",
    "    dataset['train_pos'] = train_edges\n",
    "    dataset['train_neg'] = train_edges_false\n",
    "    if(validation_size != None):\n",
    "        train_edges, val_edges = train_test_split(train_edges, test_size=validation_size)\n",
    "        train_edges_false, val_edges_false = train_test_split(train_edges_false, test_size=validation_size)\n",
    "        dataset['train_pos'] = train_edges\n",
    "        dataset['train_neg'] = train_edges_false\n",
    "        dataset['val_pos'] = val_edges\n",
    "        dataset['val_neg'] = val_edges_false\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph(adj)\n",
    "adj = nx.to_scipy_sparse_matrix(g)\n",
    "# Remove diagonal elements\n",
    "adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "adj.eliminate_zeros()\n",
    "\n",
    "adj_matrix = adj.todense()\n",
    "train_genes = int(len(adj_matrix)*.75)\n",
    "train_adj = adj_matrix[:train_genes,:train_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3383, 3383)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 1128)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_adj = adj_matrix[train_genes:,train_genes:]\n",
    "test_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset_for_generalization(train_adj, validation_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 3383\n",
      "Total edges: 158930.0\n",
      "Training edges (positive): 71518\n",
      "Training edges (negative): 71518\n",
      "Validation edges (positive): 7947\n",
      "Validation edges (negative): 7947\n"
     ]
    }
   ],
   "source": [
    "train_edges = train_dataset['train_pos']\n",
    "train_edges_false = train_dataset['train_neg']\n",
    "val_edges = train_dataset['val_pos']\n",
    "val_edges_false = train_dataset['val_neg']\n",
    "\n",
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", train_adj.shape[0])\n",
    "print(\"Total edges:\", np.sum(train_adj))  # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print(\"Training edges (positive):\", len(train_edges))\n",
    "print(\"Training edges (negative):\", len(train_edges_false))\n",
    "print(\"Validation edges (positive):\", len(val_edges))\n",
    "print(\"Validation edges (negative):\", len(val_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = create_dataset_for_generalization(test_adj, validation_size=None, gene_split=train_adj.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes: 1128\n",
      "Total edges: 21046.0\n",
      "Test edges (positive): 10523\n",
      "Test edges (negative): 10523\n"
     ]
    }
   ],
   "source": [
    "test_edges = test_dataset['train_pos']\n",
    "test_edges_false = test_dataset['train_neg']\n",
    "\n",
    "# Inspect train/test split\n",
    "print(\"Total nodes:\", test_adj.shape[0])\n",
    "print(\"Total edges:\", np.sum(test_adj))  # adj is symmetric, so nnz (num non-zero) = 2*num_edges\n",
    "print(\"Test edges (positive):\", len(test_edges))\n",
    "print(\"Test edges (negative):\", len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_rows = set(map(tuple, train_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2_rows = set(map(tuple, test_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_rows.isdisjoint(a2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1_rows = set(map(tuple, train_edges_false))\n",
    "a2_rows = set(map(tuple, test_edges_false))\n",
    "a1_rows.isdisjoint(a2_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_file = path + 'expression_data.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Nodes\n",
      "attr_M: 805\n",
      "id_N: 4511\n",
      "Reading training links\n",
      "Constructing Neighborhood maps\n",
      "Constructing train data\n"
     ]
    }
   ],
   "source": [
    "Data = data.LoadData(path, train_links=train_edges, features_file=feature_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71518"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10523"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_edges =  np.concatenate([val_edges, val_edges_false])\n",
    "val_edge_labels = np.concatenate([np.ones(len(val_edges)), np.zeros(len(val_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1,\n",
       " 'attr_embedding_size': 128,\n",
       " 'batch_size': 128,\n",
       " 'epoch': 20,\n",
       " 'id_embedding_size': 128,\n",
       " 'learning_rate': 0.002,\n",
       " 'n_neg_samples': 10,\n",
       " 'representation_size': 128}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {}\n",
    "parameters['id_embedding_size'] = 128\n",
    "parameters['attr_embedding_size'] = 128\n",
    "parameters['batch_size'] = 128\n",
    "parameters['alpha'] = 1\n",
    "parameters['n_neg_samples'] = 10\n",
    "parameters['epoch'] = 20\n",
    "parameters['representation_size'] = 128\n",
    "parameters['learning_rate'] = 0.002\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id_embedding_size': 128, 'attr_embedding_size': 128, 'batch_size': 128, 'alpha': 1, 'n_neg_samples': 10, 'epoch': 20, 'representation_size': 128, 'learning_rate': 0.002}\n"
     ]
    }
   ],
   "source": [
    "model = GNE(path, Data, 2018, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using structure and attribute embedding\n",
      "Epoch:      1, Train-Batch Loss: 7.890777881, Validation AUC: 0.586608005 *\n",
      "Epoch:      2, Train-Batch Loss: 4.407956974, Validation AUC: 0.622778734 *\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-22c54c345e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_edge_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GNE/GNE.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, validation_edges, validation_labels)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;31m# Train the model with batch of data and compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GNE/GNE.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# run the graph to compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings, attr_weights = model.train(validation_edges, val_edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(attr_weights).to_csv(\"attribute_weights_ecoli.txt\", header=False, index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafile = path + 'data_standard.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_csv(datafile, index_col=0, header=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings =  np.dot(attributes, attr_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = attributes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-set edge embeddings\n",
    "pos_train_edge_embs = get_edge_embeddings(embeddings, train_edges)\n",
    "neg_train_edge_embs = get_edge_embeddings(embeddings, train_edges_false)\n",
    "train_edge_embs = np.concatenate([pos_train_edge_embs, neg_train_edge_embs])\n",
    "# Create train-set edge labels: 1 = real edge, 0 = false edge\n",
    "train_edge_labels = np.concatenate([np.ones(len(train_edges)), np.zeros(len(train_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test-set edge embeddings, labels\n",
    "pos_test_edge_embs = get_edge_embeddings(embeddings, test_edges)\n",
    "neg_test_edge_embs = get_edge_embeddings(embeddings, test_edges_false)\n",
    "test_edge_embs = np.concatenate([pos_test_edge_embs, neg_test_edge_embs])\n",
    "\n",
    "# Create val-set edge labels: 1 = real edge, 0 = false edge\n",
    "test_edge_labels = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.random.permutation([i for i in range(len(train_edge_labels))])\n",
    "train_data = train_edge_embs[index,:]\n",
    "train_labels = train_edge_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.random.permutation([i for i in range(len(test_edge_labels))])\n",
    "test_data = test_edge_embs[index,:]\n",
    "test_labels = test_edge_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression classifier on train-set edge embeddings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "edge_classifier = LogisticRegression(random_state=0)\n",
    "edge_classifier.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds = edge_classifier.predict_proba(test_data)[:, 1]\n",
    "test_roc = roc_auc_score(test_labels, test_preds)\n",
    "test_ap = average_precision_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test ROC score: ', str(test_roc))\n",
    "print('Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yeast\n",
    "# Only using attribute embeddings with 90% nodes as training to predict interactions of remaining 10% nodes\n",
    "# Test ROC score:  0.636207024495\n",
    "# Test AP score:  0.619662145155\n",
    "\n",
    "# logistic regression of expression data \n",
    "# Test ROC score:  0.618279048852\n",
    "# Test AP score:  0.597478518784\n",
    "\n",
    "# correlation\n",
    "# Test ROC score:  0.568089255807\n",
    "# Test AP score:  0.568394943682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yeast\n",
    "# Only using attribute embeddings with 75% nodes as training to predict interactions of remaining 25% nodes\n",
    "# Test ROC score:  0.64579528764\n",
    "# Test AP score:  0.629618217338\n",
    "# logistic regression of expression data \n",
    "# Test ROC score:  0.639091808068\n",
    "# Test AP score:  0.615704858074\n",
    "# correlation\n",
    "# Test ROC score:  0.579982316533\n",
    "# Test AP score:  0.57969109199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Yeast\n",
    "# Only using attribute embeddings with 50% nodes as training to predict interactions of remaining 50% nodes\n",
    "# Test ROC score:  0.632323760642\n",
    "# Test AP score:  0.618320422841\n",
    "# logistic regression of expression data \n",
    "# Test ROC score:  0.637106649428\n",
    "# Test AP score:  0.617446089276\n",
    "# correlation\n",
    "# Test ROC score:  0.577860323413\n",
    "# Test AP score:  0.579623105575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ecoli\n",
    "# Only using attribute embeddings with 90% nodes as training to predict interactions of remaining 10% nodes\n",
    "# Test ROC score:  0.637298544227\n",
    "# Test AP score:  0.624893907808\n",
    "# logistic regression of expression data \n",
    "# Test ROC score:  0.630899399184\n",
    "# Test AP score:  0.613969657994\n",
    "# correlation\n",
    "# Test ROC score:  0.536818673513\n",
    "# Test AP score:  0.557680007943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ecoli\n",
    "# Only using attribute embeddings with 75% nodes as training to predict interactions of remaining 25% nodes\n",
    "\n",
    "# logistic regression of expression data \n",
    "\n",
    "\n",
    "# correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ecoli\n",
    "# Only using attribute embeddings with 50% nodes as training to predict interactions of remaining 50% nodes\n",
    "\n",
    "# logistic regression of expression data \n",
    "\n",
    "\n",
    "# correlation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges_cor =  np.concatenate([test_edges, test_edges_false]).astype(int)\n",
    "test_edge_labels_cor = np.concatenate([np.ones(len(test_edges)), np.zeros(len(test_edges_false))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(test_edges_cor)):\n",
    "    index = test_edges_cor[i,:]\n",
    "    row, col = index[0], index[1]\n",
    "    y_predict.append(corr[row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_roc = roc_auc_score(test_edge_labels_cor, y_predict)\n",
    "test_ap = average_precision_score(test_edge_labels_cor, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test ROC score: ', str(test_roc))\n",
    "print('Test AP score: ', str(test_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
